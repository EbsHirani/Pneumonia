{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PneumoniaModelTrainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfyQy9kBZkik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Pneumonia\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkogUaiNaVvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import load\n",
        "train = load(\"train_img.npy\")\n",
        "train_labels = load(\"train_labels.npy\")\n",
        "test = load(\"test_img.npy\")\n",
        "test_labels = load(\"test_labels.npy\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bywks-1VNOFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import cv2\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense , Dropout , Lambda, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam ,RMSprop\n",
        "from keras.optimizers import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import  backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import BatchNormalization, Convolution2D , MaxPooling2D, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AWDnTzXOWtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ohe = OneHotEncoder()\n",
        "train_enc = ohe.fit_transform(train_labels.reshape(-1,1))\n",
        "test_enc = ohe.transform(test_labels.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFRd3f3rQEEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_enc = train_enc.toarray()\n",
        "test_enc = test_enc.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA7-v87RQkgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9163680e-176e-4e7a-e384-7cb4f6886333"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "model = VGG16(weights='imagenet', include_top=False, input_shape = (224, 224, 3))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWIXeCwGQtWB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "261735f5-849a-4d1a-a676-2b317267d022"
      },
      "source": [
        "for layer in model.layers[:-2]:\n",
        "  layer.trainable = False\n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dense(1024, activation = \"relu\")(x)\n",
        "predictions = Dense(3, activation=\"softmax\")(x)\n",
        "tl_model = Model(input = model.input ,  output = predictions)\n",
        "tl_model.compile(Adam(), loss = \"categorical_crossentropy\", metrics=['accuracy'] )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNnNL5mNRIqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen = ImageDataGenerator(\n",
        "  shear_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  horizontal_flip=True    \n",
        ")\n",
        "batches=gen.flow(train,train_enc,batch_size = 16, shuffle = True)\n",
        "valbatches = gen.flow(test, test_enc, batch_size = 16, shuffle = True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f0df_08S3Xf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "35af0e97-5a88-4b30-c984-3452dffa4a56"
      },
      "source": [
        "history=tl_model.fit_generator(generator=batches, steps_per_epoch=batches.n//batches.batch_size, epochs=10, validation_data=valbatches, validation_steps=valbatches.n//valbatches.batch_size,callbacks=[EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto') ,ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True)])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "326/326 [==============================] - 87s 267ms/step - loss: 0.4715 - accuracy: 0.7962 - val_loss: 0.3931 - val_accuracy: 0.7949\n",
            "Epoch 2/10\n",
            "326/326 [==============================] - 86s 262ms/step - loss: 0.4780 - accuracy: 0.7995 - val_loss: 1.1863 - val_accuracy: 0.7965\n",
            "Epoch 3/10\n",
            "326/326 [==============================] - 84s 259ms/step - loss: 0.4591 - accuracy: 0.8039 - val_loss: 1.1669 - val_accuracy: 0.7788\n",
            "Epoch 4/10\n",
            "326/326 [==============================] - 85s 262ms/step - loss: 0.4455 - accuracy: 0.8089 - val_loss: 0.2703 - val_accuracy: 0.7853\n",
            "Epoch 5/10\n",
            "326/326 [==============================] - 86s 264ms/step - loss: 0.4589 - accuracy: 0.8037 - val_loss: 0.5207 - val_accuracy: 0.8045\n",
            "Epoch 6/10\n",
            "326/326 [==============================] - 85s 262ms/step - loss: 0.4335 - accuracy: 0.8135 - val_loss: 0.3813 - val_accuracy: 0.8221\n",
            "Epoch 7/10\n",
            "326/326 [==============================] - 85s 262ms/step - loss: 0.4522 - accuracy: 0.8041 - val_loss: 1.1524 - val_accuracy: 0.7131\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}